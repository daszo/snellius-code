_n_gpu:
    value: 1
_name_or_path:
    value: ./local_models/google/mt5-base
_wandb:
    value:
        cli_version: 0.23.1
        e:
            jej4a25xlxy7e1idb801o59brwhgnf45:
                args:
                    - --task
                    - DSI
                    - --model_name
                    - ./local_models/google/mt5-base
                    - --run_name
                    - enron-10k-mt5-base-DSI-Q-classic
                    - --max_length
                    - "32"
                    - --output_dir
                    - models/enron-10k-mt5-base-DSI-Q-classic
                    - --learning_rate
                    - "0.0005"
                    - --warmup_steps
                    - "100000"
                    - --per_device_train_batch_size
                    - "32"
                    - --per_device_eval_batch_size
                    - "32"
                    - --evaluation_strategy
                    - steps
                    - --eval_steps
                    - "1000"
                    - --max_steps
                    - "1000000"
                    - --save_strategy
                    - steps
                    - --dataloader_num_workers
                    - "10"
                    - --save_steps
                    - "1000"
                    - --save_total_limit
                    - "2"
                    - --load_best_model_at_end
                    - --gradient_accumulation_steps
                    - "1"
                    - --report_to
                    - wandb
                    - --logging_steps
                    - "100"
                    - --dataloader_drop_last
                    - "False"
                    - --metric_for_best_model
                    - Hits@10
                    - --greater_is_better
                    - "True"
                    - --remove_prompt
                    - "True"
                    - --db_name
                    - data/enron.db
                    - --table_name
                    - N10k_text_rank_d2q_q1
                codePath: run.py
                codePathLocal: run.py
                cpu_count: 72
                cpu_count_logical: 72
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "270185361408"
                        used: "5067575296"
                email: daniel@vanoosteroom.com
                executable: /gpfs/work5/0/prjs1828/DSI-QG/.venv/bin/python
                git:
                    commit: 4cb17c38394bf225a3f185174cb7f834bb170714
                    remote: git@github.com:daszo/snellius-code.git
                gpu: NVIDIA A100-SXM4-40GB
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "42949672960"
                      name: NVIDIA A100-SXM4-40GB
                      uuid: GPU-c9457b51-bd78-c789-734c-07f0b889637d
                host: gcn64.local.snellius.surf.nl
                memory:
                    total: "540634701824"
                os: Linux-5.14.0-427.92.1.el9_4.x86_64-x86_64-with-glibc2.34
                program: /gpfs/work5/0/prjs1828/DSI-QG/run.py
                python: CPython 3.9.18
                root: /gpfs/work5/0/prjs1828/DSI-QG
                slurm:
                    cluster_name: snellius
                    conf: /var/spool/slurm/slurmd/conf-cache/slurm.conf
                    cpu_bind: quiet,mask_cpu:0x00003FFFF000000000
                    cpu_bind_list: "0x00003FFFF000000000"
                    cpu_bind_type: 'mask_cpu:'
                    cpu_bind_verbose: quiet
                    cpus_on_node: "18"
                    eclibr: "0"
                    ecplug: "1"
                    erlast: srun
                    ersrun: "1"
                    export_env: ALL
                    gpus: "1"
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: gisr113267
                    job_cpus_per_node: "18"
                    job_end_time: "1765971763"
                    job_gid: "75473"
                    job_group: dvoosteroom
                    job_id: "17652665"
                    job_name: bash
                    job_nodelist: gcn64
                    job_num_nodes: "1"
                    job_partition: gpu_a100
                    job_qos: normal
                    job_start_time: "1765968163"
                    job_uid: "76013"
                    job_user: dvoosteroom
                    jobid: "17652665"
                    launch_node_ipaddr: 172.18.63.192
                    localid: "0"
                    mpi_type: pmi2
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: gcn64
                    nprocs: "1"
                    ntasks: "1"
                    oom_kill_step: "0"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "40001"
                    pty_win_col: "210"
                    pty_win_row: "54"
                    script_context: prolog_task
                    srun_comm_host: 172.18.63.192
                    srun_comm_port: "43647"
                    step_gpus: "2"
                    step_gres: gres/cpu:0
                    step_id: "0"
                    step_launcher_port: "43647"
                    step_nodelist: gcn64
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_resv_ports: 12339-12340
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /gpfs/work5/0/prjs1828/DSI-QG
                    submit_host: int6.local.snellius.surf.nl
                    task_pid: "2305567"
                    tasks_per_node: "1"
                    topology_addr: root.ibsw26.gcn64
                    topology_addr_pattern: switch.switch.node
                    umask: "0027"
                startedAt: "2025-12-17T11:06:08.485010Z"
                writerId: jej4a25xlxy7e1idb801o59brwhgnf45
        m:
            - "1": train/global_step
              "6":
                - 3
              "7": []
            - "2": '*'
              "5": 1
              "6":
                - 1
              "7": []
        python_version: 3.9.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
            "2":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
            "3":
                - 1
                - 7
                - 13
                - 66
            "4": 3.9.18
            "5": 0.23.1
            "6": 4.21.0
            "12": 0.23.1
            "13": linux-x86_64
adafactor:
    value: false
adam_beta1:
    value: 0.9
adam_beta2:
    value: 0.999
adam_epsilon:
    value: 1e-08
add_cross_attention:
    value: false
architectures:
    value:
        - MT5ForConditionalGeneration
auto_find_batch_size:
    value: false
bad_words_ids:
    value: null
bf16:
    value: false
bf16_full_eval:
    value: false
bos_token_id:
    value: null
chunk_size_feed_forward:
    value: 0
classifier_dropout:
    value: 0
cross_attention_hidden_size:
    value: null
d_ff:
    value: 2048
d_kv:
    value: 64
d_model:
    value: 768
data_seed:
    value: None
dataloader_drop_last:
    value: false
dataloader_num_workers:
    value: 10
dataloader_pin_memory:
    value: true
ddp_bucket_cap_mb:
    value: None
ddp_find_unused_parameters:
    value: None
debug:
    value: '[]'
decoder_start_token_id:
    value: 0
deepspeed:
    value: None
dense_act_fn:
    value: gelu_new
disable_tqdm:
    value: false
diversity_penalty:
    value: 0
do_eval:
    value: true
do_predict:
    value: false
do_sample:
    value: false
do_train:
    value: false
dropout_rate:
    value: 0.1
dtype:
    value: float32
early_stopping:
    value: false
encoder_no_repeat_ngram_size:
    value: 0
eos_token_id:
    value: 1
eval_accumulation_steps:
    value: None
eval_batch_size:
    value: 32
eval_delay:
    value: 0
eval_steps:
    value: 1000
evaluation_strategy:
    value: steps
exponential_decay_length_penalty:
    value: null
feed_forward_proj:
    value: gated-gelu
finetuning_task:
    value: null
forced_bos_token_id:
    value: null
forced_eos_token_id:
    value: null
fp16:
    value: false
fp16_backend:
    value: auto
fp16_full_eval:
    value: false
fp16_opt_level:
    value: O1
fsdp:
    value: '[]'
fsdp_min_num_params:
    value: 0
fsdp_transformer_layer_cls_to_wrap:
    value: None
full_determinism:
    value: false
gradient_accumulation_steps:
    value: 1
gradient_checkpointing:
    value: false
greater_is_better:
    value: true
group_by_length:
    value: false
half_precision_backend:
    value: auto
hub_model_id:
    value: None
hub_private_repo:
    value: false
hub_strategy:
    value: every_save
hub_token:
    value: <HUB_TOKEN>
id2label:
    value:
        "0": LABEL_0
        "1": LABEL_1
ignore_data_skip:
    value: false
include_inputs_for_metrics:
    value: false
initializer_factor:
    value: 1
is_decoder:
    value: false
is_encoder_decoder:
    value: true
is_gated_act:
    value: true
jit_mode_eval:
    value: false
label_names:
    value: None
label_smoothing_factor:
    value: 0
label2id:
    value:
        LABEL_0: 0
        LABEL_1: 1
layer_norm_epsilon:
    value: 1e-06
learning_rate:
    value: 0.0005
length_column_name:
    value: length
length_penalty:
    value: 1
load_best_model_at_end:
    value: true
local_rank:
    value: 0
log_level:
    value: -1
log_level_replica:
    value: -1
log_on_each_node:
    value: true
logging_dir:
    value: models/enron-10k-mt5-base-DSI-Q-classic/runs/Dec17_12-06-07_gcn64.local.snellius.surf.nl
logging_first_step:
    value: false
logging_nan_inf_filter:
    value: true
logging_steps:
    value: 100
logging_strategy:
    value: steps
lr_scheduler_type:
    value: linear
max_grad_norm:
    value: 1
max_length:
    value: 20
max_steps:
    value: 1000000
metric_for_best_model:
    value: Hits@10
min_length:
    value: 0
model_type:
    value: mt5
mp_parameters:
    value: ""
no_cuda:
    value: false
no_repeat_ngram_size:
    value: 0
num_beam_groups:
    value: 1
num_beams:
    value: 1
num_decoder_layers:
    value: 12
num_heads:
    value: 12
num_layers:
    value: 12
num_return_sequences:
    value: 1
num_train_epochs:
    value: 3
optim:
    value: adamw_hf
output_attentions:
    value: false
output_dir:
    value: models/enron-10k-mt5-base-DSI-Q-classic
output_hidden_states:
    value: false
output_past:
    value: true
output_scores:
    value: false
overwrite_output_dir:
    value: false
pad_token_id:
    value: 0
past_index:
    value: -1
per_device_eval_batch_size:
    value: 32
per_device_train_batch_size:
    value: 32
per_gpu_eval_batch_size:
    value: None
per_gpu_train_batch_size:
    value: None
prediction_loss_only:
    value: false
prefix:
    value: null
problem_type:
    value: null
push_to_hub:
    value: false
push_to_hub_model_id:
    value: None
push_to_hub_organization:
    value: None
push_to_hub_token:
    value: <PUSH_TO_HUB_TOKEN>
ray_scope:
    value: last
relative_attention_max_distance:
    value: 128
relative_attention_num_buckets:
    value: 32
remove_invalid_values:
    value: false
remove_unused_columns:
    value: true
repetition_penalty:
    value: 1
report_to:
    value: '[''wandb'']'
resume_from_checkpoint:
    value: None
return_dict:
    value: true
return_dict_in_generate:
    value: false
run_name:
    value: enron-10k-mt5-base-DSI-Q-classic
save_on_each_node:
    value: false
save_steps:
    value: 1000
save_strategy:
    value: steps
save_total_limit:
    value: 2
seed:
    value: 42
sep_token_id:
    value: null
sharded_ddp:
    value: '[]'
skip_memory_metrics:
    value: true
task_specific_params:
    value: null
temperature:
    value: 1
tf_legacy_loss:
    value: false
tf32:
    value: None
tie_encoder_decoder:
    value: false
tie_word_embeddings:
    value: false
tokenizer_class:
    value: T5Tokenizer
top_k:
    value: 50
top_p:
    value: 1
torch_dtype:
    value: null
torchdynamo:
    value: None
torchscript:
    value: false
tpu_metrics_debug:
    value: false
tpu_num_cores:
    value: None
train_batch_size:
    value: 32
transformers_version:
    value: 4.21.0
typical_p:
    value: 1
use_bfloat16:
    value: false
use_cache:
    value: true
use_ipex:
    value: false
use_legacy_prediction_loop:
    value: false
vocab_size:
    value: 250112
warmup_ratio:
    value: 0
warmup_steps:
    value: 100000
weight_decay:
    value: 0
xpu_backend:
    value: None
